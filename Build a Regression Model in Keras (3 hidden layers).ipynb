{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download check and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data doesn't contain null values\n"
     ]
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
    "#concrete_data.describe()\n",
    "#are nulls in the dataset?\n",
    "if (concrete_data.isnull().sum()!=0).any:\n",
    "    print(\"The data doesn't contain null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "1. We split into predictors and target\n",
    "2. Normalize predictors\n",
    "3. Store # of Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "\n",
    "#Normalized the predictors\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "n_cols = predictors_norm.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the function to create and compile the regresion model\n",
    "1. One hidden layer of 10 nodes, and a ReLU activation function\n",
    "2. Optimized adam loss mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train and test the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 out of 50\n",
      "['loss', 'mean_squared_error'] [147.86181640625, 147.86181640625]\n",
      "Processing 2 out of 50\n",
      "['loss', 'mean_squared_error'] [95.78158569335938, 95.78158569335938]\n",
      "Processing 3 out of 50\n",
      "['loss', 'mean_squared_error'] [64.61528015136719, 64.61528015136719]\n",
      "Processing 4 out of 50\n",
      "['loss', 'mean_squared_error'] [53.78757858276367, 53.78757858276367]\n",
      "Processing 5 out of 50\n",
      "['loss', 'mean_squared_error'] [51.29718017578125, 51.29718017578125]\n",
      "Processing 6 out of 50\n",
      "['loss', 'mean_squared_error'] [47.27583312988281, 47.27583312988281]\n",
      "Processing 7 out of 50\n",
      "['loss', 'mean_squared_error'] [47.837852478027344, 47.837852478027344]\n",
      "Processing 8 out of 50\n",
      "['loss', 'mean_squared_error'] [46.5609016418457, 46.5609016418457]\n",
      "Processing 9 out of 50\n",
      "['loss', 'mean_squared_error'] [47.209564208984375, 47.209564208984375]\n",
      "Processing 10 out of 50\n",
      "['loss', 'mean_squared_error'] [44.96909713745117, 44.96909713745117]\n",
      "Processing 11 out of 50\n",
      "['loss', 'mean_squared_error'] [44.74009704589844, 44.74009704589844]\n",
      "Processing 12 out of 50\n",
      "['loss', 'mean_squared_error'] [44.92049026489258, 44.92049026489258]\n",
      "Processing 13 out of 50\n",
      "['loss', 'mean_squared_error'] [44.39302444458008, 44.39302444458008]\n",
      "Processing 14 out of 50\n",
      "['loss', 'mean_squared_error'] [44.537654876708984, 44.537654876708984]\n",
      "Processing 15 out of 50\n",
      "['loss', 'mean_squared_error'] [44.19886016845703, 44.19886016845703]\n",
      "Processing 16 out of 50\n",
      "['loss', 'mean_squared_error'] [44.48276138305664, 44.48276138305664]\n",
      "Processing 17 out of 50\n",
      "['loss', 'mean_squared_error'] [45.77888488769531, 45.77888488769531]\n",
      "Processing 18 out of 50\n",
      "['loss', 'mean_squared_error'] [45.04658889770508, 45.04658889770508]\n",
      "Processing 19 out of 50\n",
      "['loss', 'mean_squared_error'] [44.7636833190918, 44.7636833190918]\n",
      "Processing 20 out of 50\n",
      "['loss', 'mean_squared_error'] [45.45479965209961, 45.45479965209961]\n",
      "Processing 21 out of 50\n",
      "['loss', 'mean_squared_error'] [45.62882995605469, 45.62882995605469]\n",
      "Processing 22 out of 50\n",
      "['loss', 'mean_squared_error'] [47.492958068847656, 47.492958068847656]\n",
      "Processing 23 out of 50\n",
      "['loss', 'mean_squared_error'] [45.35138702392578, 45.35138702392578]\n",
      "Processing 24 out of 50\n",
      "['loss', 'mean_squared_error'] [46.35286331176758, 46.35286331176758]\n",
      "Processing 25 out of 50\n",
      "['loss', 'mean_squared_error'] [46.736541748046875, 46.736541748046875]\n",
      "Processing 26 out of 50\n",
      "['loss', 'mean_squared_error'] [46.13264846801758, 46.13264846801758]\n",
      "Processing 27 out of 50\n",
      "['loss', 'mean_squared_error'] [49.513980865478516, 49.513980865478516]\n",
      "Processing 28 out of 50\n",
      "['loss', 'mean_squared_error'] [48.07988739013672, 48.07988739013672]\n",
      "Processing 29 out of 50\n",
      "['loss', 'mean_squared_error'] [51.21463394165039, 51.21463394165039]\n",
      "Processing 30 out of 50\n",
      "['loss', 'mean_squared_error'] [49.53078079223633, 49.53078079223633]\n",
      "Processing 31 out of 50\n",
      "['loss', 'mean_squared_error'] [50.34416961669922, 50.34416961669922]\n",
      "Processing 32 out of 50\n",
      "['loss', 'mean_squared_error'] [48.8332633972168, 48.8332633972168]\n",
      "Processing 33 out of 50\n",
      "['loss', 'mean_squared_error'] [49.32399368286133, 49.32399368286133]\n",
      "Processing 34 out of 50\n",
      "['loss', 'mean_squared_error'] [49.80766296386719, 49.80766296386719]\n",
      "Processing 35 out of 50\n",
      "['loss', 'mean_squared_error'] [48.872802734375, 48.872802734375]\n",
      "Processing 36 out of 50\n",
      "['loss', 'mean_squared_error'] [48.69268035888672, 48.69268035888672]\n",
      "Processing 37 out of 50\n",
      "['loss', 'mean_squared_error'] [47.984317779541016, 47.984317779541016]\n",
      "Processing 38 out of 50\n",
      "['loss', 'mean_squared_error'] [49.14406204223633, 49.14406204223633]\n",
      "Processing 39 out of 50\n",
      "['loss', 'mean_squared_error'] [48.05709457397461, 48.05709457397461]\n",
      "Processing 40 out of 50\n",
      "['loss', 'mean_squared_error'] [48.37043762207031, 48.37043762207031]\n",
      "Processing 41 out of 50\n",
      "['loss', 'mean_squared_error'] [44.835906982421875, 44.835906982421875]\n",
      "Processing 42 out of 50\n",
      "['loss', 'mean_squared_error'] [46.84016799926758, 46.84016799926758]\n",
      "Processing 43 out of 50\n",
      "['loss', 'mean_squared_error'] [46.59307861328125, 46.59307861328125]\n",
      "Processing 44 out of 50\n",
      "['loss', 'mean_squared_error'] [46.220428466796875, 46.220428466796875]\n",
      "Processing 45 out of 50\n",
      "['loss', 'mean_squared_error'] [45.59415054321289, 45.59415054321289]\n",
      "Processing 46 out of 50\n",
      "['loss', 'mean_squared_error'] [45.37828826904297, 45.37828826904297]\n",
      "Processing 47 out of 50\n",
      "['loss', 'mean_squared_error'] [46.43414306640625, 46.43414306640625]\n",
      "Processing 48 out of 50\n",
      "['loss', 'mean_squared_error'] [46.53114318847656, 46.53114318847656]\n",
      "Processing 49 out of 50\n",
      "['loss', 'mean_squared_error'] [45.38471984863281, 45.38471984863281]\n",
      "Processing 50 out of 50\n",
      "['loss', 'mean_squared_error'] [46.243019104003906, 46.243019104003906]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "nIter = 50\n",
    "for n in range(nIter):\n",
    "    print(\"Processing\", n+1, \"out of\", nIter)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.30, random_state=1)\n",
    "    history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(model.metrics_names, metrics)\n",
    "    data = [metrics]\n",
    "    df = pd.concat([pd.DataFrame(data, columns = model.metrics_names),df])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean: 50.42067153930664\n",
      "Standard Deviation: 15.805791427364557\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(df[\"mean_squared_error\"])\n",
    "\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Mean: \"+str(mean))\n",
    "print(\"Standard Deviation: \"+str(standard_deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
