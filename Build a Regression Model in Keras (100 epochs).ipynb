{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download check and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data doesn't contain null values\n"
     ]
    }
   ],
   "source": [
    "concrete_data = pd.read_csv('https://cocl.us/concrete_data')\n",
    "#concrete_data.describe()\n",
    "#are nulls in the dataset?\n",
    "if (concrete_data.isnull().sum()!=0).any:\n",
    "    print(\"The data doesn't contain null values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "1. We split into predictors and target\n",
    "2. Normalize predictors\n",
    "3. Store # of Columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_data_columns = concrete_data.columns\n",
    "predictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\n",
    "target = concrete_data['Strength'] # Strength column\n",
    "\n",
    "#Normalized the predictors\n",
    "predictors_norm = (predictors - predictors.mean()) / predictors.std()\n",
    "\n",
    "n_cols = predictors_norm.shape[1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the function to create and compile the regresion model\n",
    "1. One hidden layer of 10 nodes, and a ReLU activation function\n",
    "2. Optimized adam loss mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We train and test the network\n",
    "1. 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = regression_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1 out of 50\n",
      "['loss', 'mean_squared_error'] [222.06149291992188, 222.06149291992188]\n",
      "Processing 2 out of 50\n",
      "['loss', 'mean_squared_error'] [146.39166259765625, 146.39166259765625]\n",
      "Processing 3 out of 50\n",
      "['loss', 'mean_squared_error'] [99.10488891601562, 99.10488891601562]\n",
      "Processing 4 out of 50\n",
      "['loss', 'mean_squared_error'] [75.8990249633789, 75.8990249633789]\n",
      "Processing 5 out of 50\n",
      "['loss', 'mean_squared_error'] [66.18508911132812, 66.18508911132812]\n",
      "Processing 6 out of 50\n",
      "['loss', 'mean_squared_error'] [61.523765563964844, 61.523765563964844]\n",
      "Processing 7 out of 50\n",
      "['loss', 'mean_squared_error'] [58.8924446105957, 58.8924446105957]\n",
      "Processing 8 out of 50\n",
      "['loss', 'mean_squared_error'] [56.892494201660156, 56.892494201660156]\n",
      "Processing 9 out of 50\n",
      "['loss', 'mean_squared_error'] [55.611473083496094, 55.611473083496094]\n",
      "Processing 10 out of 50\n",
      "['loss', 'mean_squared_error'] [54.388938903808594, 54.388938903808594]\n",
      "Processing 11 out of 50\n",
      "['loss', 'mean_squared_error'] [53.985435485839844, 53.985435485839844]\n",
      "Processing 12 out of 50\n",
      "['loss', 'mean_squared_error'] [53.75241470336914, 53.75241470336914]\n",
      "Processing 13 out of 50\n",
      "['loss', 'mean_squared_error'] [53.55216598510742, 53.55216598510742]\n",
      "Processing 14 out of 50\n",
      "['loss', 'mean_squared_error'] [53.66141891479492, 53.66141891479492]\n",
      "Processing 15 out of 50\n",
      "['loss', 'mean_squared_error'] [53.571083068847656, 53.571083068847656]\n",
      "Processing 16 out of 50\n",
      "['loss', 'mean_squared_error'] [53.498104095458984, 53.498104095458984]\n",
      "Processing 17 out of 50\n",
      "['loss', 'mean_squared_error'] [53.55155944824219, 53.55155944824219]\n",
      "Processing 18 out of 50\n",
      "['loss', 'mean_squared_error'] [53.37117004394531, 53.37117004394531]\n",
      "Processing 19 out of 50\n",
      "['loss', 'mean_squared_error'] [53.45296859741211, 53.45296859741211]\n",
      "Processing 20 out of 50\n",
      "['loss', 'mean_squared_error'] [53.411598205566406, 53.411598205566406]\n",
      "Processing 21 out of 50\n",
      "['loss', 'mean_squared_error'] [53.229591369628906, 53.229591369628906]\n",
      "Processing 22 out of 50\n",
      "['loss', 'mean_squared_error'] [53.276371002197266, 53.276371002197266]\n",
      "Processing 23 out of 50\n",
      "['loss', 'mean_squared_error'] [53.40634536743164, 53.40634536743164]\n",
      "Processing 24 out of 50\n",
      "['loss', 'mean_squared_error'] [53.26030349731445, 53.26030349731445]\n",
      "Processing 25 out of 50\n",
      "['loss', 'mean_squared_error'] [53.59534454345703, 53.59534454345703]\n",
      "Processing 26 out of 50\n",
      "['loss', 'mean_squared_error'] [53.37031555175781, 53.37031555175781]\n",
      "Processing 27 out of 50\n",
      "['loss', 'mean_squared_error'] [53.68201446533203, 53.68201446533203]\n",
      "Processing 28 out of 50\n",
      "['loss', 'mean_squared_error'] [53.59535598754883, 53.59535598754883]\n",
      "Processing 29 out of 50\n",
      "['loss', 'mean_squared_error'] [53.436241149902344, 53.436241149902344]\n",
      "Processing 30 out of 50\n",
      "['loss', 'mean_squared_error'] [53.41313934326172, 53.41313934326172]\n",
      "Processing 31 out of 50\n",
      "['loss', 'mean_squared_error'] [53.37900161743164, 53.37900161743164]\n",
      "Processing 32 out of 50\n",
      "['loss', 'mean_squared_error'] [53.43357467651367, 53.43357467651367]\n",
      "Processing 33 out of 50\n",
      "['loss', 'mean_squared_error'] [53.44287109375, 53.44287109375]\n",
      "Processing 34 out of 50\n",
      "['loss', 'mean_squared_error'] [53.50046157836914, 53.50046157836914]\n",
      "Processing 35 out of 50\n",
      "['loss', 'mean_squared_error'] [53.618919372558594, 53.618919372558594]\n",
      "Processing 36 out of 50\n",
      "['loss', 'mean_squared_error'] [53.652130126953125, 53.652130126953125]\n",
      "Processing 37 out of 50\n",
      "['loss', 'mean_squared_error'] [53.623817443847656, 53.623817443847656]\n",
      "Processing 38 out of 50\n",
      "['loss', 'mean_squared_error'] [53.60481643676758, 53.60481643676758]\n",
      "Processing 39 out of 50\n",
      "['loss', 'mean_squared_error'] [53.83951950073242, 53.83951950073242]\n",
      "Processing 40 out of 50\n",
      "['loss', 'mean_squared_error'] [53.712188720703125, 53.712188720703125]\n",
      "Processing 41 out of 50\n",
      "['loss', 'mean_squared_error'] [53.658729553222656, 53.658729553222656]\n",
      "Processing 42 out of 50\n",
      "['loss', 'mean_squared_error'] [53.79967498779297, 53.79967498779297]\n",
      "Processing 43 out of 50\n",
      "['loss', 'mean_squared_error'] [53.72042465209961, 53.72042465209961]\n",
      "Processing 44 out of 50\n",
      "['loss', 'mean_squared_error'] [53.869361877441406, 53.869361877441406]\n",
      "Processing 45 out of 50\n",
      "['loss', 'mean_squared_error'] [53.93645095825195, 53.93645095825195]\n",
      "Processing 46 out of 50\n",
      "['loss', 'mean_squared_error'] [53.95882034301758, 53.95882034301758]\n",
      "Processing 47 out of 50\n",
      "['loss', 'mean_squared_error'] [54.00354766845703, 54.00354766845703]\n",
      "Processing 48 out of 50\n",
      "['loss', 'mean_squared_error'] [53.926513671875, 53.926513671875]\n",
      "Processing 49 out of 50\n",
      "['loss', 'mean_squared_error'] [54.041072845458984, 54.041072845458984]\n",
      "Processing 50 out of 50\n",
      "['loss', 'mean_squared_error'] [54.10026550292969, 54.10026550292969]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "nIter = 50\n",
    "for n in range(nIter):\n",
    "    print(\"Processing\", n+1, \"out of\", nIter)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.30, random_state=1)\n",
    "    history = model.fit(X_train, y_train, validation_split=0.3, epochs=100, verbose=0)\n",
    "    metrics = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(model.metrics_names, metrics)\n",
    "    data = [metrics]\n",
    "    df = pd.concat([pd.DataFrame(data, columns = model.metrics_names),df])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Mean: 60.83692756652832\n",
      "Standard Deviation: 27.278427540074883\n"
     ]
    }
   ],
   "source": [
    "mean_squared_errors = np.array(df[\"mean_squared_error\"])\n",
    "\n",
    "mean = np.mean(mean_squared_errors)\n",
    "standard_deviation = np.std(mean_squared_errors)\n",
    "\n",
    "print('\\n')\n",
    "print(\"Mean: \"+str(mean))\n",
    "print(\"Standard Deviation: \"+str(standard_deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
